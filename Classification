########################################
## Orion Darley
## Charity Project - Part 2 (The Classification Problem)
##
## SampleCodePart2.R
########################################

# Load packages required for this code.
library(pROC)
library(glmnet)
library(rpart)
library(e1071)
library(leaps)
library(tree)
library(randomForest)
library(ggcorrplot)
library(pastecs)
library(aplpack)
library(Hmisc)
library(rpart.plot)
library(ggbiplot)
library(nFactors)

################################################################################
## Exercise 1
## Read Data from CSV File
################################################################################

inPath = file.path("~/")

classData = read.csv(file.path(inPath,"projectDataPart2.csv"),na.strings=c("NA"," "))

# Convert categorical variables to factors
# This is highly recommended so that R treats the variables appropriately.
# The lm() method in R can handle a factor variable without us needing to convert 
# the factor to binary dummy variable(s).

classData$DONR = as.factor(classData$DONR)
classData$HOME = as.factor(classData$HOME)
classData$HINC = as.factor(classData$HINC)

########################################
## Exercise 2
## Data Quality Check
########################################

dim(classData)      # dimensions of data
names(classData)    # variable names
str(classData)      # one form of summary of data
summary(classData)  # another form of summary
stat.desc(classData)

## Check for Missing Values
which(saply(classData,anyNA))

# There are no true char strings in this dataset.
# Turn them into factors / categorical variables.
stringsAsFactors = TRUE

# Missing values identified in HINC, GENDER, and RFA_96
# Get counts of missing values for each variable
table(classData$HINC,useNA="ifany")
table(classData$GENDER,useNA="ifany")
table(classData$RFA_96,useNA="ifany")

#Remove variables
classData = classData[-3]

# Outlier detection 
attach(classData)
par(mfrow = c(1,3))
boxplot(MEDHVAL, xlab = "MEDHVAL", col = "steelblue3", cex.axis=1.5, cex.lab = 1.5)
boxplot(MEDINC, xlab = "MEDINC", col = "steelblue3", cex.axis=1.5, cex.lab = 1.5)
boxplot(RAMNTALL, xlab = "RAMNTALL", col = "steelblue3", cex.axis=1.5, cex.lab = 1.5)
par(mfrow = c(1,1))

bagplot(RAMNTALL, DONR, xlab = "Lifetime Contributions ($US)", ylab = "Individual Contributions ($US)",
        main = "Using Bagplots in Outlier Detection", xlim=c(0, 750), ylim=c(0, 75))
bagplot(MEDINC)
bagplot(RAMNTALL)

########################################
## Exercise 3
## Exploratory Data Analysis
########################################

attach(classData)

numeric.cd = data.frame(DONR, AGE, HOME, MEDAGE, MEDPPH, MEDHVAL, MEDINC, 
MEDEDUC, NUMPROM, NUMPRM12, RAMNTALL, NGIFTALL, MAXRAMNT,LASTGIFT, TDON)
numeric.cd$DONR = as.numeric(numeric.cd$DONR); numeric.cd$AGE = as.numeric(numeric.cd$AGE)
numeric.cd$HOME = as.numeric(numeric.cd$HOME); numeric.cd$NGIFTALL = as.numeric(numeric.cd$NGIFTALL);
numeric.cd$MEDAGE = as.numeric(numeric.cd$MEDAGE); numeric.cd$MEDHVAL = as.numeric(numeric.cd$MEDHVAL);
numeric.cd$MEDPPH = as.numeric(numeric.cd$MEDPPH); numeric.cd$MEDINC = as.numeric(numeric.cd$MEDINC);
numeric.cd$MEDEDUC = as.numeric(numeric.cd$MEDEDUC); numeric.cd$NUMPROM = as.numeric(numeric.cd$NUMPROM);
numeric.cd$NUMPRM12 = as.numeric(numeric.cd$NUMPRM12); str(numeric.cd)
#numeric.cd = log(numeric.cd[1:15]+1); str(numeric.cd)

# Maximum Likelihood Factor Analysis
# Entering raw data and extracting 3 factors with varimax rotation 
fit <- factanal(numeric.cd, 5, rotation="varimax")
print(fit, digits=2, cutoff=.3, sort=TRUE)
# Plot factor 1 x factor 2 
load <- fit$loadings[,1:2] 
plot(load,type="n", main = "Maximum Likelihood Factor Analysis") # set up plot 
text(load,labels=names(numeric.cd),cex=1.3) # add variable names

# Determine Number of Factors to Extract
ev <- eigen(cor(numeric.cd)) # get eigenvalues
ap <- parallel(subject=nrow(numeric.cd),var=ncol(numeric.cd),
               rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)

#Principal Component Analysis
pca <- princomp(numeric.cd, cor=TRUE)
summary(pca) #print variance accounted for 
loadings(pca) #pc loadings 
plot(pca,type="lines", main = "Scree Plot of the ClassData set (numeric only)", col = "Steelblue3", ylim = c(0,5)) # scree plot 
pca$scores #the principal components
biplot(pca, main = "PCA")

solution = fa(r = cor.cd, nfactors = 4); summary(solution)

######################################################################################
## Better PCA graphics supplied by Vince Vu @ http://www.vince.vu/software/#ggbiplot
numeric.cd.pca <- prcomp(numeric.cd, scale. = TRUE)
##Class variable might require debugging
ggbiplot(numeric.cd.pca, obs.scale = 1, var.scale = 1,
         ellipse = TRUE, circle = TRUE) +
  scale_color_discrete(name = '') +
  theme(legend.direction = 'horizontal', legend.position = 'top')
ggscreeplot(numeric.cd.pca)
######################################################################################

# Counts of the response variable DONR
table(classData$DONR)
barplot(table(classData$DONR),xlab="DONR", ylim = c(0, 100000), ylab = "Counts",
        col = "steelblue3", main = "Counts of the response variable DONR")

# Counts for a categorical predictor variable
table(classData$GENDER,useNA="ifany")
barplot(table(classData$GENDER,useNA="ifany"),xlab="GENDER", ylim = c(0, 75000), ylab = "Counts",
        col = "steelblue3", main = "Counts of the response variable DONR")

# Boxplot of AGE by DONR status
# In order for R to make this into a boxplot, DONR needs to be a factor variable
# and DONR needs to be plotted on the horizontal axis.
plot(classData$DONR,classData$AGE,xlab="DONR",ylab="AGE")

# Plot response against a categorical variable
# "Wrong" Way
# The following barplot is an accurate presentation of the data. I call it the 
# "wrong" way because students have a tendency to draw the wrong conclusions from
# this graph.
barplot(table(classData$GENDER[classData$DONR == 1]),
        xlab="GENDER",main="Barplot of GENDER for DONR = 1")
# This graph shows that there are more female donors than male donors. Therefore, 
# it seems reasonable to conclude that a female is more likely to donate. However,
# if you were to look at the non-donors, you would see that there are more female 
# non-donors than male non-donors. What this graph is showing us is that females
# outnumber males in the dataset as a whole, not that females are more likely to 
# donate.

# "Right" Way
# A mosaic plot is obtained when we plot one factor variable against another. The
# mosaic plot represents the counts as proportions to the whole. A deviation in
# overall proportion of females donating compared to males donating is meaningful
# whereas the absolute count of females donating compared to males donating was not.
plot(classData$DONR,classData$GENDER,xlab="DONR",ylab="GENDER",main="Mosaic Plot")
# Or
plot(classData$GENDER,classData$DONR,xlab="GENDER",ylab="DONR",main="Mosaic Plot")
# These graphs show that M/F doesn't show any difference in DONR status.

#Variables with the highest amount of correlation with the target variable
par(mfrow = c(1,3))
plot(classData$LASTGIFT,classData$DAMT,xlab="Dollar amount of most recent gift",ylab="Donation ($)", col = "steelblue3",
     main = "", ylim=c(0, 100))
lm_age = lm(DAMT ~ LASTGIFT, data=classData)
abline(lm_age,col="red")
plot(classData$RAMNTALL,classData$DAMT,xlab="Dollar amount of lifetime gifts to date",ylab="Donation ($)", col = "steelblue3",
     main = "", ylim=c(0, 100))
lm_age = lm(RAMNTALL ~ LASTGIFT, data=classData)
abline(lm_age,col="red")
plot(classData$MAXRAMNT,classData$DAMT,xlab="Dollar amount of largest gift to date",ylab="Donation ($)", col = "steelblue3",
     main = "", ylim=c(0, 100))
lm_age = lm(MAXRAMNT ~ LASTGIFT, data=classData)
abline(lm_age,col="red")
par(oma=c(0,0,2,0)); title("Possible Predictor Variables: RAMNTALL, LASTGIFT, MAXRAMNT", outer=TRUE)
par(mfrow = c(1,1))

#Checking for overdispersion
sapply(classData[,3:19], var)
sapply(classData[,3:19], mean)

#other 
hist(DAMT)

########################################
## Exercise 4
## Data Preparation
########################################

## Part A - Resolve Missing Values

# HINC - Make a level 0 and code missing values as 0
levels(classData$HINC) = c(levels(classData$HINC),"0")
classData$HINC[is.na(classData$HINC)] = "0"
table(classData$HINC,useNA="ifany")

# GENDER - Assign A, J, and NA to category U
idxMF = classData$GENDER %in% c("M","F")
classData$GENDER[!idxMF] = "U"
classData$GENDER = factor(classData$GENDER)
table(classData$GENDER)

# RFA_96 - Make a level XXX and code missing values as XXX
levels(classData$RFA_96) = c(levels(classData$RFA_96),"XXX")
classData$RFA_96[is.na(classData$RFA_96)] = "XXX"
table(classData$RFA_96,useNA="ifany")

# Log Transformations / merged into dataframe classData
#classData$MEDHVAL.LOG = log(MEDHVAL)
#classData$MEDINC.LOG = log(MEDINC)
#classData$RAMNTALL.LOG = log(RAMNTALL)

#Remove non-log variable versions
#classData = classData[-"MEDHVAL"]
#classData = classData[-MEDINC]
#classData = classData[-RAMNTALL]
str(classData)

## Part C - Re-categorize Variables

# Separate RFA Values (R = recency, F = frequency, A = amount)
# Note: I wrote a function (separateRFA) to perform these steps.
separateRFA = function(xData,varName)
{
  bytes = c("R","F","A")
  newVarNames = paste(varName,bytes, sep="_")
  
  for (ii in 1:length(bytes)) # Loop over 1 to 3 (corresponding to R, F, and A)
  {
    # Find the unique values for current byte
    byteVals = unique(substr(levels(xData[,varName]),ii,ii))
    
    for (jj in 1:length(byteVals)) # Loop over unique byte values
    {
      rowIdx = substr(xData[,varName],ii,ii) == byteVals[jj]
      xData[rowIdx,newVarNames[ii]] = byteVals[jj]
    }
    
    xData[,newVarNames[ii]] = factor(xData[,newVarNames[ii]])
  }
  
  return(xData)
}

# Apply separateRFA to the variables RFA_96 and RFA_97
classData = separateRFA(classData,"RFA_96")
classData = separateRFA(classData,"RFA_97")

# Check the results
table(classData$RFA_96,classData$RFA_96_R)
table(classData$RFA_96,classData$RFA_96_F)
table(classData$RFA_96,classData$RFA_96_A)
table(classData$RFA_97,classData$RFA_97_R)
table(classData$RFA_97,classData$RFA_97_F)
table(classData$RFA_97,classData$RFA_97_A)

dropIdx = which(names(classData) %in% c("DAMT","RFA_96","RFA_97","RFA_97_R"))

# Drop the variables indicated by dropIdx.
classData2 = classData[,-dropIdx]
names(classData2)   # check that the result is as expected

########################################
## Exercise 5
## Dataset Partitioning
########################################

testFraction = 0.25   # specify the fraction of data to use in the hold-out test 
set.seed(1234)

# 1) Logical 
# - the index vector has length equal to the number of observations 
# - the index values are boolean (TRUE and FALSE)
# - TRUE = use that row in the sample, FALSE = do not use that row in the sample

trainIdx = sample(c(TRUE,FALSE),size=nrow(classData2),replace=TRUE,
                  prob=c(1-testFraction,testFraction))

par(mfrow = c(1,2))
hist(train$DAMT, main = "", col = "Steelblue3", xlab = "Training Set DAMT")
hist(test$DAMT, main = "", col = "Steelblue3", xlab = "Test Set DAMT")
par(oma=c(0,0,2,0)); title("Training and Test Set Distribution of DAMT", outer=TRUE)
par(mfrow = c(1,1))

stat.desc(train$DAMT)
stat.desc(test$DAMT)

########################################
## Exercise 6
## Model Fitting
########################################

## Part A - Simple Logistic Regression
modelA1 = glm(DONR ~ TDON,data=classData2,subset=trainIdx,family=binomial)
summary(modelA1)
par(mfrow=c(2,2))
plot(modelA1, col = "Steelblue3")
par(mfrow=c(1,1))
anova(modelA1)

# Note that fitting the logistic model is only the first part of the classification
# task. The logistic model provides a score for the likelihood that an individual
# will donate. We must select a cutoff or threshold value to use for translating
# the score to a 0/1 classification result.

# In general, a default threshold of 0.5 can be used. However, there are two problems
# with this strategy.
#  1) A default value of 0.5 assumes that the 0-class and 1-class are represented
#  equally in the training dataset. If that assumption fails, then 0.5 will not work
#  well as a cutoff.
#  2) The default value of 0.5 is not necessarily optimal. We should generate a ROC
#  curve in order to assess the potential for a more optimal threshold and to 
#  evaluate the cost-benefit of a particular threshold in terms of FP-TP rates.

# As you may have observed in EDA, the DONR=1 class represents approximately 5%
# of the dataset. This explains why the logistic regression scores are on the scale
# of 0.05. As such, using the default cutoff of 0.5 would result in all individuals
# being classified as non-donors. While this would be a very unhelpful classifcation
# model, it would have 95% accuracy since the model would be incorrect only 5% of 
# the time.

par(mfrow = c(1,3))
trnProbsA1 = predict(modelA1,type="response")
hist(trnProbsA1,col="steelblue3")   # Note that scores are distributed around 0.05.
hist(trnProbsA1,col="steelblue3", main = "SLR Model 1 Predictions", ylim=c(0,25000), xlim = c(0.02, .1))   # Rescale to make obvious.
mean(trnProbsA1)

# ROC Curve for Model A1 - Use methods from pROC package.
rocA1 = roc(response=classData$DONR[trainIdx],predictor=trnProbsA1)
par(pty="s")  # sets plotting region to a square, useful for ROC curves
# Use par(pty="m") to return to default of rectangular plotting region.
plot(rocA1,col="blue",
     main=paste("ROC curve for Model A1\nAUC = ",round(rocA1$auc,digits=3),sep=""))
par(pty="m")
par(mfrow = c(1,1))

# Determine "optimal" threshold.
# Note: There is no single rule to define an "optimal" threshold. We must apply
# our own judgment within the context of the classification problem.
# 
# One rule of thumb for determining an optimal point on the ROC curve is to select 
# the point closest to the upper-left corner (coordinates (0,1)). This rule gives 
# equal weight to TP and FP. We know that is not appropriate in some cases.
# Note: Since the ROC curve is plotted with Specificity on the horizontal axis
# (instead of FP, where FP = 1-Specificity) and the horizontal axis goes
# from 1 down to 0, I will be using the coordinates (1,1) in the distance formula.

dist01 = sqrt((rocA1$specificities-1)^2 + (rocA1$sensitivities-1)^2)
optIdxA1 = which.min(dist01)  # index corresponding to minimum distance
threshA1 = rocA1$thresholds[optIdxA1]  # threshold corresponding to min. distance
points(rocA1$specificities[optIdxA1],rocA1$sensitivities[optIdxA1],col="red",pch=7)

# A few notes on the ROC curve.
#  1) Given the ROC curve we get for the charity classification problem, there don't
#  appear to be a lot of great choices for the threshold. Recall that we are not
#  going to get a particularly good classification model on this problem (though
#  it won't matter so much when we get to Part 3 of the project).
#  2) A better ROC curve would go higher into the top-left corner. Therefore, you
#  could find a threshold that provides a much higher TP for much lower FP. We don't
#  see that scenario with this project.
#  3) Depending on the context of the classification problem, you may only be able
#  to tolerate a certain amount of FP or you may be able to tolerate quite a bit of
#  FP.
#  4) For the mailing problem, FPs are cheap (we mail to a non-donor at a cost of
#  $0.68) and FNs (or missed TPs) are comparably more expensive (we lose out on a 
#  donation that has an average value of $15.62). If you are interested in 
#  incorporating these relative weights into the classification model, then
#  you could replace the dist01 calculation above with the following:
#     sqrt((0.68*(rocA1$specificities-1))^2 + (15.62*(rocA1$sensitivities-1)^2))
#  Note that if you do so, you will end up with a tremendous number of FPs but you
#  should end up capturing most of the TPs.

##########################
# ML Regression ModelB1
modelB1 = glm(DONR ~ .-ID,data=classData2,subset=trainIdx,family=binomial)
summary(modelB1)

# ROC Curve for Model A1 - Use methods from pROC package.
trnProbsB1 = predict(modelB1,type="response")
rocB1 = roc(response=classData$DONR[trainIdx],predictor=trnProbsB1)
par(pty="s")  # sets plotting region to a square, useful for ROC curves
plot(rocB1,col="blue",
     main=paste("ROC curve for Model B1\nAUC = ",round(rocB1$auc,digits=3),sep=""))
par(pty="m")

# Determine "optimal" threshold.
dist01 = sqrt((rocB1$specificities-1)^2 + (rocB1$sensitivities-1)^2)
optIdxB1 = which.min(dist01)  # index corresponding to minimum distance
threshB1 = rocB1$thresholds[optIdxB1]  # threshold corresponding to min. distance
points(rocB1$specificities[optIdxB1],rocB1$sensitivities[optIdxB1],col="red",pch=7)

##########################
# ML Regression ModelB2
modelB2 = glm(DONR ~ TDON + NUMPROM + RFA_97_A + RFA_97_F + HINC
+ MEDHVAL + NUMPRM12,data=classData2,subset=trainIdx,family=binomial)
summary(modelB2)
plot(modelB2, col = "Steelblue3")

par(mfrow = c(1,3))
trnProbsB2 = predict(modelB2,type="response")
hist(trnProbsB2,col="steelblue3", ylim=c(0,20000), xlim=c(0, 0.2))   # Note that scores are distributed around 0.05.
hist(trnProbsB2,col="steelblue3", main = "MLR Model 2 Predictions", ylim=c(0,15000), xlim=c(0, 0.2))   # Rescale to make obvious.
mean(trnProbsB2)

# ROC Curve for Model B2 - Use methods from pROC package.
trnProbsB2 = predict(modelB2,type="response")
rocB2 = roc(response=classData$DONR[trainIdx],predictor=trnProbsB2)
par(pty="s")  # sets plotting region to a square, useful for ROC curves
plot(rocB2,col="blue",
     main=paste("ROC curve for Model B2\nAUC = ",round(rocB2$auc,digits=3),sep=""))
par(pty="m")
par(mfrow = c(1,1))

# Determine "optimal" threshold.
dist01 = sqrt((rocB2$specificities-1)^2 + (rocB2$sensitivities-1)^2)
optIdxB2 = which.min(dist01)  # index corresponding to minimum distance
threshB2 = rocB2$thresholds[optIdxB2]  # threshold corresponding to min. distance
points(rocB2$specificities[optIdxB2],rocB2$sensitivities[optIdxB2],col="red",pch=7)

## Part C - Tree-Based Models
# A few notes about fitting a classification tree to the charity data.
#  1) tree(DONR ~ .-ID,data=classData2,subset=trainIdx) gives you a single node tree
#  This is not desirable for a classification model. Basically, every individual is
#  labelled a non-donor (as with logistic regression and a cutoff of 0.5).
#  2) One thing we can do to result in the tree method building more
#  than a single node tree, is set split="gini". See pp. 311-12 of ISLR for 
#  discussion of the Gini index.
#  3) When we set split="gini", we next get an error that maximum tree depth has
#  been reached. We can ameliorate this error by selecting fewer variables in the
#  model formula (I started with DONR ~ .-ID). I believe this error results from
#  limitations in the way the tree method is implemented.
#  4) Having said all that, with the formula 
#     DONR ~  NGIFTALL + MAXRAMNT + LASTGIFT + TDON
#  I got a tree with 2185 nodes. When I tried to run cv.tree to look at pruning 
#  the tree, I got an error about a singlenode tree that I was unable to resolve.
#  5) The tree package is not the most widely used package for building trees; rpart
#  is much more common. Therefore, I am switching to using the rpart package.
#  6) The rpart method requires some parameter settings in order for it to build 
#  a tree of more than a single node. The parameters are: 
#     method="class" (should be the default setting when DONR is a factor variable, 
#       but at this point it doesn't hurt to be explicit)
#     split="gini" (same as with the tree method)
#     loss=matrix(0,15.62,0.68,0) (sets cost parameters: $0.68 for FP and $15.62 
#       for FN)

fullTree = rpart(DONR ~  .-ID,
                 data=classData2,subset=trainIdx,method="class",
                 parms=list(split="gini",loss=matrix(c(0,15.62,0.68,0),nrow=2,ncol=2)))
summary(fullTree)

fullTree = rpart(DONR ~  NGIFTALL + MAXRAMNT + LASTGIFT + TDON,
                data=classData2,subset=trainIdx,method="class",
                parms=list(split="gini",loss=matrix(c(0,15.62,0.68,0),nrow=2,ncol=2)))
summary(fullTree)
plot(fullTree)
text(fullTree)

# Prune the tree
printcp(fullTree)
cpBest = fullTree$cptable[which.min(fullTree$cptable[,"xerror"]),"CP"]
modelC1 = prune(fullTree,cp=cpBest) # In this case, the optimal tree is the unpruned tree
summary(modelC1)
plot(modelC1)
text(modelC1,pretty=0)

## Part D - SVM Model
svmRadial = svm(DONR ~  NGIFTALL + MAXRAMNT + LASTGIFT + TDON,data=classData2,
              subset=trainIdx,kernel="radial")
summary(svmRadial)

# Note: It will take a while to plot all data points. I recommend taking a random
# sample for the sake of speedier visualization.
if (class(trainIdx) %in% c("integer","numeric")) # trainIdx is numeric
{
  sampleIdx = sample(trainIdx,size=0.1*length(trainIdx))
} else # trainIdx is logical
{
  sampleIdx = sample(which(trainIdx),size=0.1*sum(trainIdx))
}
plot(svmRadial,data=classData2[sampleIdx,],NGIFTALL~TDON)

# Tune SVM model
# I'm getting excessively long run times in trying to tune the SVM model.
# tuneLinear=tune(svm,DONR ~ NGIFTALL + MAXRAMNT + LASTGIFT + TDON,
#                 data=classData2[trainIdx,],kernel="linear",
#                 ranges=list(cost=c(1,5)),sampling="fix")
# summary(tuneLinear)
modelD1 = svmRadial

########################################
## Exercise 7
## Model Validation
########################################

# For each model, I will generate predictions for all data (Train and Test). I
# will then calculate the Train and Test Classification Accuracy, Confusion Matrices,
# and TP and FP Rates by subsetting the predictions accordingly. The following 
# functions will perform those tasks for me.
assignClass = function(probVals,threshVal)
{
  predVals = rep(0,length(probVals))
  predVals[probVals > threshVal] = 1
  predVals = factor(predVals)
  
  return(predVals)
}

calcMetrics = function(targetVals,predVals)
{
  confMat = table(targetVals,predVals,dnn=c("Target","Predicted"))
  
  classResults = list(
    confMat = confMat,
    TPrate = round(confMat[2,2] / sum(confMat[2,]),digits=4),
    FPrate = round(confMat[1,2] / sum(confMat[1,]),digits=4),
    accuracy = round(mean(targetVals == predVals),digits=2)
  )
  
  return(classResults)
}

calcResults = function(model,modelLabel,dataSet,trainIdx,threshVal=NULL)
{
  if (!is.null(threshVal) & "glm" %in% class(model)) {
    # Predict for glm models
    probVals = predict(model,dataSet,type="response")
    predVals = assignClass(probVals,threshVal)
  } else if (length(intersect(class(model),c("tree","rpart","randomForest")) > 0)) {
    # Predict for tree, rpart, randomForest models
    predVals = predict(model,dataSet,type="class")
  } else if (length(intersect(class(model),c("lda")) > 0)) {
    # Predict for lda models
    predVals = predict(model,dataSet)$class
  } else if (length(intersect(class(model),c("svm")) > 0)) {
    # Predict for svm models
    predVals = predict(model,dataSet)
  }
    
  results = list(
    name = modelLabel,
    train = calcMetrics(classData2$DONR[trainIdx],predVals[trainIdx]),
    test = calcMetrics(classData2$DONR[-trainIdx],predVals[-trainIdx])
  )
  
  return(results)
}

nModels = 4 # Number of models you fit. I fit 4 models in this sample code.
naTmp = rep(NA,nModels) # Code short-hand.
nanTmp = rep(NaN,nModels)
modelMetrics = data.frame(
  Model = naTmp,
  Train.Accuracy = nanTmp, Train.TP = nanTmp, Train.FP = nanTmp,
  Test.Accuracy = nanTmp, Test.TP = nanTmp, Test.FP = nanTmp
  )

resultsA1 = calcResults(modelA1,"A1",classData2,trainIdx,threshA1)
print(resultsA1$test$confMat)
modelMetrics[1,] = c(resultsA1$name,
                     resultsA1$train$accuracy,resultsA1$train$TPrate,resultsA1$train$FPrate,
                     resultsA1$test$accuracy,resultsA1$test$TPrate,resultsA1$test$FPrate)

resultsB1 = calcResults(modelB1,"B1",classData2,trainIdx,threshB1)
print(resultsB1$test$confMat)
modelMetrics[2,] = c(resultsB1$name,
                     resultsB1$train$accuracy,resultsB1$train$TPrate,resultsB1$train$FPrate,
                     resultsB1$test$accuracy,resultsB1$test$TPrate,resultsB1$test$FPrate)

resultsC1 = calcResults(modelC1,"C1",classData2,trainIdx)
print(resultsC1$test$confMat)
modelMetrics[3,] = c(resultsC1$name,
                     resultsC1$train$accuracy,resultsC1$train$TPrate,resultsC1$train$FPrate,
                     resultsC1$test$accuracy,resultsC1$test$TPrate,resultsC1$test$FPrate)

resultsD1 = calcResults(modelD1,"D1",classData2,trainIdx)
print(resultsD1$test$confMat)
modelMetrics[4,] = c(resultsD1$name,
                     resultsD1$train$accuracy,resultsD1$train$TPrate,resultsD1$train$FPrate,
                     resultsD1$test$accuracy,resultsD1$test$TPrate,resultsD1$test$FPrate)

print(modelMetrics)
